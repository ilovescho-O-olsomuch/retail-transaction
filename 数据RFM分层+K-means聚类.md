## åŸºæœ¬ä»£ç 
``` python
import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# ================================================
# 1. è¯»å–æ•°æ®ï¼ˆç¡®ä¿ CustomerID ä¸ºå­—ç¬¦ä¸²ï¼‰
# ================================================
file_path = r"C:\Users\32165\Desktop\cleaned_retail.csv"
df = pd.read_csv(file_path, dtype={"CustomerID": str}, parse_dates=["TransactionDate"])

# **è®°å½• CustomerID åŸå§‹é¡ºåº**
df["OriginalOrder"] = df.index  # æ·»åŠ ç´¢å¼•ï¼Œä»£è¡¨åŸå§‹é¡ºåº

# ================================================
# 2. è®¡ç®—åŸºå‡†æ—¥æœŸï¼ˆæœ€å¤§äº¤æ˜“æ—¥æœŸçš„æ¬¡æœˆ1æ—¥ï¼‰
# ================================================
max_date = df["TransactionDate"].max()
if max_date.month == 12:
    cutoff_date = datetime(max_date.year + 1, 1, 1)
else:
    cutoff_date = datetime(max_date.year, max_date.month + 1, 1)

print(f"\nåŸºå‡†æ—¥æœŸï¼ˆæ¬¡æœˆ1æ—¥ï¼‰ï¼š{cutoff_date.strftime('%Y-%m-%d')}")

# ================================================
# 3. è®¡ç®— RFM æŒ‡æ ‡
# ================================================
rfm = df.groupby("CustomerID", as_index=False).agg(
    Recency=("TransactionDate", lambda x: (cutoff_date - x.max()).days),  # æœ€è¿‘è´­ä¹°å¤©æ•°
    Frequency=("TransactionDate", "count"),  # è´­ä¹°æ¬¡æ•°
    Monetary=("TotalAmount", "sum")  # æ€»æ¶ˆè´¹é‡‘é¢
)

# ================================================
# 4. æ•°æ®æ ‡å‡†åŒ–ï¼ˆK-means å¿…éœ€ï¼‰
# ================================================
scaler = StandardScaler()
rfm_scaled = scaler.fit_transform(rfm[["Recency", "Frequency", "Monetary"]])
rfm_scaled_df = pd.DataFrame(rfm_scaled, columns=["Recency", "Frequency", "Monetary"])

# ================================================
# 5. K-means èšç±»ï¼ˆåˆ†æˆ 4 ç»„ï¼‰
# ================================================
kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
rfm["Cluster"] = kmeans.fit_predict(rfm_scaled_df)

# å®šä¹‰åˆ†ç¾¤æ ‡ç­¾
cluster_labels = {
    0: "æµå¤±å®¢æˆ·",
    1: "ä¸€èˆ¬å®¢æˆ·",
    2: "é«˜ä»·å€¼å®¢æˆ·",
    3: "æ½œåŠ›å®¢æˆ·"
}
rfm["Cluster_Label"] = rfm["Cluster"].map(cluster_labels)

# ================================================
# 6. æ¢å¤åŸå§‹é¡ºåº
# ================================================
rfm = df[["CustomerID", "OriginalOrder"]].drop_duplicates().merge(rfm, on="CustomerID", how="left")
rfm = rfm.sort_values("OriginalOrder").drop(columns=["OriginalOrder"])  # æŒ‰åŸå§‹é¡ºåºæ’åºï¼Œå¹¶åˆ é™¤è¾…åŠ©åˆ—

# ================================================
# 7. å¯¼å‡ºåˆ†ç¾¤ç»“æœï¼Œç¡®ä¿ CustomerID æ­£ç¡®
# ================================================
output_path = r"C:\Users\32165\Desktop\customer_segments.csv"
try:
    rfm.to_csv(output_path, index=False, quoting=1)  # quoting=1 é¿å… CustomerID å˜å½¢
    print("\nâœ… RFM è®¡ç®—å®Œæˆï¼Œåˆ†ç¾¤ç»“æœå·²ä¿å­˜è‡³:", output_path)
    print("\nğŸ“Š åˆ†ç¾¤ç»“æœç¤ºä¾‹ï¼š")
    print(rfm.head())
except PermissionError:
    print("\nâŒ é”™è¯¯ï¼šæ–‡ä»¶å¯èƒ½è¢«å ç”¨ï¼Œè¯·å…³é—­ Excel æˆ–æ›´æ¢ä¿å­˜è·¯å¾„ã€‚")

# ================================================
# 8. åˆ†ç¾¤ç»“æœç»Ÿè®¡ï¼ˆéªŒè¯ç”¨ï¼‰
# ================================================
print("\nğŸ“Œ åˆ†ç¾¤ç»Ÿè®¡ï¼š")
print(rfm["Cluster_Label"].value_counts())
